<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Building a Spam Classifier | Ainulindalë</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Building a Spam Classifier" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We all face the problem of spam e-mails in our inboxes. Data show that the total volume of spam mails has been consistently growing in time to the point that nowadays it overtakes the amount of ordinary or ham emails. Estimates tell us that 97% of all emails sent over the Internet in 2008 were unwanted 1. Most of the spam is already fitered out by our providers, but still, quite a few spam emails are able to evade these filters and make their way to us. To better detect the unwanted spam the best way is probably to train an ad hoc filter, tuned on our own mails. Contrary to what you could think this isn’t a hard task which can be realized with a little of machine learning. Wikipedia/spam”&gt;Wikipedia/spam repo &#8617;" />
<meta property="og:description" content="We all face the problem of spam e-mails in our inboxes. Data show that the total volume of spam mails has been consistently growing in time to the point that nowadays it overtakes the amount of ordinary or ham emails. Estimates tell us that 97% of all emails sent over the Internet in 2008 were unwanted 1. Most of the spam is already fitered out by our providers, but still, quite a few spam emails are able to evade these filters and make their way to us. To better detect the unwanted spam the best way is probably to train an ad hoc filter, tuned on our own mails. Contrary to what you could think this isn’t a hard task which can be realized with a little of machine learning. Wikipedia/spam”&gt;Wikipedia/spam repo &#8617;" />
<link rel="canonical" href="http://localhost:4000/ainulindale/jekyll/update/2019/12/19/Building-a-Spam-Classifier.html" />
<meta property="og:url" content="http://localhost:4000/ainulindale/jekyll/update/2019/12/19/Building-a-Spam-Classifier.html" />
<meta property="og:site_name" content="Ainulindalë" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-12-19T00:00:00+00:00" />
<script type="application/ld+json">
{"description":"We all face the problem of spam e-mails in our inboxes. Data show that the total volume of spam mails has been consistently growing in time to the point that nowadays it overtakes the amount of ordinary or ham emails. Estimates tell us that 97% of all emails sent over the Internet in 2008 were unwanted 1. Most of the spam is already fitered out by our providers, but still, quite a few spam emails are able to evade these filters and make their way to us. To better detect the unwanted spam the best way is probably to train an ad hoc filter, tuned on our own mails. Contrary to what you could think this isn’t a hard task which can be realized with a little of machine learning. Wikipedia/spam”&gt;Wikipedia/spam repo &#8617;","datePublished":"2019-12-19T00:00:00+00:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/ainulindale/jekyll/update/2019/12/19/Building-a-Spam-Classifier.html"},"url":"http://localhost:4000/ainulindale/jekyll/update/2019/12/19/Building-a-Spam-Classifier.html","headline":"Building a Spam Classifier","dateModified":"2019-12-19T00:00:00+00:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ainulindale/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/ainulindale/feed.xml" title="Ainulindalë" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/ainulindale/">Ainulindalë</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Building a Spam Classifier</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-12-19T00:00:00+00:00" itemprop="datePublished">Dec 19, 2019
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>We all face the problem of spam e-mails in our inboxes.
Data show that the total volume of spam mails has been consistently growing in time to the point that nowadays it overtakes the amount of ordinary or <em>ham</em> emails. Estimates tell us that 97% of all emails sent over the Internet in 2008 were unwanted <sup id="fnref:foot"><a href="#fn:foot" class="footnote">1</a></sup>.
Most of the spam is already fitered out by our providers, but
still, quite a few spam emails are able to evade these filters and make their way to us.</p>

<p>To better detect the unwanted spam the best way is probably to train an <em>ad hoc</em> filter, tuned on our own mails. 
Contrary to what you could think this isn’t a hard task which can be realized with a little of <strong>machine learning</strong>.</p>

<p>In this post I will describe all the steps and analysis I’ve done, in order to build my personal spam-fitler.
Given that the important concepts are general and do not rely on any programming languag, here I do not show any code. 
If you’re interested in the code - written in <strong>Python</strong> - you can it you can take a look at the Jupyter notebook I’ve used to create this post. Here’e the link to my <a href="https://github.com/LorBordin/Spam_classifier">GitHub repo</a>.</p>

<h2 id="1-getting-the-data">1. Getting the data</h2>

<p>As previously said, to build a spam-filter <strong>tuned for our (or our company) needs</strong>  one should use her/his own mails. Getting the training data in this way is easy, in my case I built up a quite large database in few months.</p>

<p>However, instead of sharing my personal messages, to make this post I’ve opted for the <a href="https://spamassassin.apache.org/old/publiccorpus/">Apache SpamAssassin’s public datasets</a>. It’s the perfect set to start with: no pre-processing at all has been made on it, the dataset consists in <em>raw</em> emails, the  same we get from the mail-box.</p>

<p>The SpamAssasins’s dataset consists in three different compressed files that contain:</p>

<ul>
  <li>2500 e-mails classified as <strong>easy ham</strong>,</li>
  <li>250 <strong>hard ham</strong> e-mails,</li>
  <li>500 <strong>spam</strong> e-mails.</li>
</ul>

<p>The first thing we have to do before starting any analysis is to split our dataset into a <strong>train</strong> and <strong>test</strong> set.
In practice we label the emails with their class (ham or spam), then we merge the sets together, shuffle and finally split the dataset in two: a bigger one (80% of the mail) and a smaller set for the final evaluation (the test set).</p>

<h2 id="2-data-cleaning">2. Data cleaning</h2>

<p>Let’s focus on the train set. We need to extract some features to train our spam-filter. A good thing to do is to look at the email content. 
Spam mails often consists in advertising messages, so they might contain some common word as <em>money</em>,  <em>opportunity</em>, <em>loan</em> or <em>mortage</em>.</p>

<p>So we want to extract the words content from each mail and build 
a list with the most common spam mails.</p>

<p>Let’s start with the words extraction part. To avoid repetitions it’s better to firstly parse the mails’ content doing the following operations:</p>

<ul>
  <li>remove all the html tags,</li>
  <li>remove punctuation,</li>
  <li>covert words in lower-case,</li>
  <li>replace numbers with <em>NUMBER</em> and urls with <em>URL</em>.</li>
</ul>

<p>If you use <em>python</em>, some packages like <code class="highlighter-rouge">email</code>, <code class="highlighter-rouge">regex</code> and  <code class="highlighter-rouge">beautifulsoup</code> are very useful for this purpose.</p>

<h2 id="3-data-analysis">3. Data Analysis</h2>

<p>We’ve extracted the words let’s <strong>count their frequency</strong>.
It is convenient to build 2 different vocabularies that count the frequency hammy and spammy words.
In doing so don’t forget to <strong>remove the english common stopwords</strong> like <em>the</em>, <em>is</em>, <em>at</em>, …, which are not useful to understand the content of the mail.
Here’s the 20 most common ham and spam words in my train dataset:</p>

<p><img src="https://raw.githubusercontent.com/LorBordin/Spam_classifier/master/images/words_freq.png" alt="" /></p>

<p>Good! Notice Words like <strong>free</strong>, <strong>money</strong>, <strong>click</strong> that appear often only in spam mails. They look like really spammy words!</p>

<p>Let’s parse the <strong>mails’ subjcet</strong>  as well: it will probably contain important info.
Let’s build a vocabulary that counts the most frequent spam’s subject words.
Here’s the 20 most common words:</p>

<p><img src="https://raw.githubusercontent.com/LorBordin/Spam_classifier/master/images/subj_spam.png" alt="" /></p>

<p>We’ve already collected a lot of interesting features. Still many other  info can be extractred from database!
For instance, many emails consist in multipart and, a closer analysis reveals that spam and ham have in general a different structure:</p>

<p><img src="https://raw.githubusercontent.com/LorBordin/Spam_classifier/master/images/email_type.png" alt="" /></p>

<p>There’s a lot of <em>plain text</em> in the ham dataset, while <em>html</em> is more frequent in the spam one. Good to know.</p>

<h2 id="4-preprocessing">4. Preprocessing</h2>

<p>It’s time to convert all the extracted features into frequency vectors. 
For each mail we create a long vector (507 entries!) that stores</p>

<ul>
  <li>the frequency if the <strong>most frequent 200 ham words</strong>,</li>
  <li>the frequency of the <strong>most frequent 250 spam words</strong>,</li>
  <li>the frequency of the <strong>most frequent 50 subject words</strong>,</li>
  <li>the <strong>email’s type</strong>.</li>
</ul>

<p>Better to <strong>rescale the features vector</strong> in order to perform better on the  Support Vector Machine algoritims.</p>

<p>To get an a-priori idea of how the emails dispose in the features space, we use the <em>t-SNE</em> algorithm that reduces the dimensionality of the features vector while trying to keep similar instances close and dissimilar instances apart.</p>

<p><img src="https://raw.githubusercontent.com/LorBordin/Spam_classifier/master/images/clustering.png" alt="" /></p>

<p>Notice how ham clusters in several regions of the pain, while spam spreads mainly in the top-right part of the plot.</p>

<p>Before training any model, let’s tackle the <strong>overfitting</strong> problem. The features vector we’ve created has a large number of entries and many of them consist in words that appear both in the ham and the spam vocabularies, so there are many repeated entries. Traininig any algorithm with such features will, most probably, overfit the data causiung the algorithm will perform poorly on the new ones. 
To avoid this problem I’ve created a function that randomly selects only a  subset of features, taking care of removing all the repetitions.
The subset length is treated as a hyper-parameter that is tuned for each classifier during the training phase.</p>

<h2 id="5-training-the-classifiers">5. Training the classifiers</h2>

<p>Time to train our filter!</p>

<p>But firstly.. What <strong>score</strong> should the maximise? 
The simplest thing we can  think is the <strong>accuracy</strong>, that just counts the number of wrong predictions</p>

<div align="center">
<img src="https://raw.githubusercontent.com/LorBordin/ainulindale/gh-pages/_images/accuracy.png" width="225" />
</div>

<p><br /></p>

<p>But, this is <strong>not a good score</strong>: our dataset consists of  only ~ 15% spam mails, so a <em>dumb filter</em> that says everything is ham would score ~ 0.85 out of 1! <br />
Moreover, accuracy considers <em>false positive</em> (FP) and <em>false negative</em> (FN) equally important. In other words it makes no distinction if ham is classified as spam (FP), or if spam is classified as ham (FN). But, of course, we care more that our spam filter does not filter out ham messages, better if it lets some spam pass instead.
So instead of accuracy it’s better to use a combination of two additional scores, <strong>precision</strong> and <strong>recall</strong>,</p>

<div align="center">
<img src="https://raw.githubusercontent.com/LorBordin/ainulindale/gh-pages/_images/prec_rec.png" width="380" />
</div>

<p><br /></p>

<p>where TP and FP stand for <em>true positive</em> and <em>false negative</em> (respectively, spam and spam classified as ham). Ideally we want to tune our filter to have the maximum possible precision - 1.0 - while keeping recall the highest possible.
Therefore, we decide to maximise the <strong>F1 score</strong>, that is the <em>harmonic mean</em> of precision and recall.</p>

<p>We chose the score, what about the classifier?<br />
Shall we train Linear model? Support Vector Machine? Random Forest? Well let’s train them all and <strong>make a voting classifier</strong>, most probably it’ll perform better than any individual classifier.
Let’s train the following algorithms:</p>

<ul>
  <li>a <strong>Logistic regressor</strong>, - a Stochastic Gradient Descent or <strong>SGD classifier</strong>,</li>
  <li>a <strong>Random Forest classifier</strong>,</li>
  <li>a <strong>K Neighbors classifier</strong>,</li>
  <li>a Support Vector Machine or <strong>SVM classifer</strong>.</li>
</ul>

<p>As previously discussed, each classifier is trained on a different feature sets. In this way not only we lower the risk of overfitting, but also the algorithms will make more uncorrelated errors and the voting classifier will perform better.</p>

<p>To get an idea of how the individual classifiers will generalise to an independent data set, <em>cross-validation</em> is a good option. It’s a tequinique that consists in dividing the train set in some validation sets (5 is a good choice), and then evaluating the classifier on each validation set, after having trained it on the rest of the data.
Here’s my results:</p>

<div align="center">
<img src="https://raw.githubusercontent.com/LorBordin/Spam_classifier/master/images/cv_performances.png" width="400" />
</div>

<p>Since the Random Forest classifier performs the best among the individual ones, its vote count twice on the voting classifier.</p>

<p>A great quality of Random Forests is that they make it easy to measure the relative importance of each feature. The following plot shows the features that contributed more than 1% in the decision process.</p>

<p><img src="https://raw.githubusercontent.com/LorBordin/Spam_classifier/master/images/feature_importances.png" alt="" /></p>

<p>So the most important feature is <em>click</em> (8%) followed by <em>please</em> and the email types <em>text/html</em> and <em>text/plain</em> (all around 5%).</p>

<h2 id="6-final-evaluation">6. Final evaluation</h2>

<p>We’ve fine-tuned and trained the algorithms, cross validated them on the train dataset and built a voting classifier. It only reamin to evaluate our filter on the test set in order to asses its performances.</p>

<p>Of course do not forget to preprocess the test set  in the same as we did for the training set before! <br />
Here’s the perfomances of the voting classifier on an unknown dataset.</p>

<div align="center">
 <img src="https://raw.githubusercontent.com/LorBordin/Spam_classifier/master/images/test_voting.png" width="200" />
</div>

<p>It performs very well, confirming the results of the cross-validation test!
Let’s take a look at the <strong>confusion matrix</strong> :</p>

<div align="center">
 <img src="https://raw.githubusercontent.com/LorBordin/Spam_classifier/master/images/confusion_matrix.png" width="300" />
</div>

<p>Wow! It misclassified only 2 ham mails; at the same time it let passed 13 spam mails out of 100. Not bad!</p>

<p>But let’s take a closer look at the misclassified ham mails:</p>

<p>The first is an advertising email form Ryanair</p>

<blockquote>
  <p>Ryanair in partnership with Primary Insurance<br />
offer excellent value travel insurance from<br />
£7.00GBP/9.00 Euro per person for 31 day cover.</p>

  <p>Annual travel insurance* from £45.00GBP/63.00 Euro,<br />
includes 24 days winter sports cover !</p>

  <p>Our travel insurance provides a high standard of cover.</p>

  <p>Summary of Cover</p>

  <p>Medical Expenses up to £2 million<br />
Personal Liability  up to £2 million <br />
Personal Effects &amp; Baggage up to £750<br />
Personal Accident Maximum Benefit £15,000</p>

  <p>…</p>
</blockquote>

<p>while the second is written in Japanese (according to Google translate)</p>

<blockquote>
  <p>OpenText社<br />
伊東様</p>

  <p>いつもお世話になっております。 
安井@infocomです。</p>

  <p>あるタスクリストに、適当なマイルストーンを複数、タスクを複数用意し<br />
それぞれのタスクについては、存在する適当なマイルストーンに割り当てたものと<br />
します。<br />
あるマイルストーンを見ると、添付の絵にあるような画面が表示されるのですが<br />
ここで丸で囲った部分（ 期間 ）は、何を意味しているのでしょうか？</p>

  <p>つまり、３７日 、２７日<br />
のそれぞれの意味（算出のされ方について教えてください。）</p>

  <p>また「週末を除く」とありますが、週末を除かない設定方法はあるのでしょうか？</p>

  <p>以上、ご回答の方よろしくお願いいたします。</p>

  <p>–
+————————————–+
インフォコム(株)<br />
ナレッジマネジメント本部<br />
KMフロンティア部<br />
コラボレーティブシステムグループ</p>

  <p>〒101-0062<br />
東京都千代田区神田駿河台3-11三井住友海上駿河台別館5F<br />
安井  剛<br />
E-mail: go@infocom.co.jp<br />
TEL: 03-3518-3299<br />
FAX: 03-3518-3055</p>
</blockquote>

<p>Here, the distinction between ham and spam gets thin, personally I’d labelled both the emails as spam.</p>

<p>Before concluding, let’s compare the performances of the individual classifiers on the test set:</p>

<div align="center">
<img src="https://raw.githubusercontent.com/LorBordin/Spam_classifier/master/images/test_performances.png" width="400" />
</div>

<p>As expected <strong>the voting classifier scores better than any individual one!</strong></p>

<h2 id="7-conclusion">7. Conclusion</h2>

<p>In this post we’ve exploited a public dataset of raw emails and in order to make a <strong>simple yet powerful spam-filter</strong> that detects most of the spam that evade the controls of our providers.</p>

<p>Again, take a look at my 
<a href="https://github.com/LorBordin/Spam_classifier">GitHub repo</a>
and in particular at the  <strong>Jupyter Notebook</strong> in it, if you want to inspect the code I used to make my filter.</p>

<!--- comment on periodically update the dictionaries and re-train the voting classifier in order to keep the filter up-to-date with the new spam e-mails. 
This is a simple task and it isn't time consuming as well. --->

<p>Let’s comment about some possibile generalisations.
Here we’ve build a spam-filter, however the same ideas can applied to other similar tasks; the code as well could be used with little changes.</p>

<p>Obvious examples are a <strong>Hate-speach detector</strong>, that classifies profiles in a social network with little modifications, or a <strong>Clickbait recognizer</strong>, that detects false advertisement from a website.</p>

<div class="footnotes">
  <ol>
    <li id="fn:foot">
      <p><a href="https://en.wikipedia.org/wiki/Email_spam#Statistics_and_estimates">Wikipedia/spam”&gt;Wikipedia/spam repo</a> <a href="#fnref:foot" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div><a class="u-url" href="/ainulindale/jekyll/update/2019/12/19/Building-a-Spam-Classifier.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ainulindale/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Ainulindalë</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ainulindalë</li><li><a class="u-email" href="mailto:lorenzo.bordin@nottingham.ac.uk">lorenzo.bordin@nottingham.ac.uk</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/LorBordin"><svg class="svg-icon"><use xlink:href="/ainulindale/assets/minima-social-icons.svg#github"></use></svg> <span class="username">LorBordin</span></a></li><li><a href="https://www.linkedin.com/in/Lorenzo-Bordin"><svg class="svg-icon"><use xlink:href="/ainulindale/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">Lorenzo-Bordin</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>I’m Lorenzo, a theoretical physicist working in Cosmology at the University of Nottingham.  Data science and Machine Learning appassionate, I’ve created this blog to share what I’ve learned in this field.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
